\relax 
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand*\new@tpo@label[2]{}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Neural Networks}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Notation}{3}{}\protected@file@percent }
\newlabel{sec:notation}{{2.1}{3}}
\newlabel{def:layer}{{2.2}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Illustration of a neuron as graph.}}{3}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Illustration of a layer as graph.}}{3}{}\protected@file@percent }
\newlabel{def:network}{{2.3}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Illustration of a neural network as graph.}}{4}{}\protected@file@percent }
\newlabel{fig:neuron}{{3}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Training in the Parameter Space}{5}{}\protected@file@percent }
\newlabel{sec:Training}{{2.2}{5}}
\citation{GD}
\citation{ConvexOptimization}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Gradient Descent}}{6}{}\protected@file@percent }
\newlabel{lem:descent}{{2.8}{7}}
\citation{ConvexOptimization}
\newlabel{thm:descent}{{2.9}{8}}
\citation{BFGS}
\newlabel{lem:convexity}{{2.12}{9}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Broyden-Fletcher-Goldfarb-Shanno (BFGS)}}{10}{}\protected@file@percent }
\citation{SGD}
\citation{Adam}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces Stochastic Gradient Descent (SGD)}}{11}{}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {4}{\ignorespaces Adaptive Moment Estimation (Adam)}}{12}{}\protected@file@percent }
\citation{NTK}
\@writefile{toc}{\contentsline {section}{\numberline {3}Training in the Function Space}{13}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Motivation}{13}{}\protected@file@percent }
\citation{Functionals}
\citation{NTK}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Functional Derivative}{14}{}\protected@file@percent }
\citation{FunctionalAnalysis}
\newlabel{lem:projection}{{3.6}{17}}
\citation{FunctionalAnalysis}
\newlabel{cor:projection}{{3.7}{18}}
\citation{FunctionalAnalysis}
\newlabel{lem:riesz}{{3.8}{19}}
\citation{NTK}
\citation{NTK}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Reproducing Kernel Hilbert Space}{21}{}\protected@file@percent }
\newlabel{lem:form}{{3.11}{21}}
\citation{RKHS}
\citation{Reproducing}
\newlabel{def:definite}{{3.12}{22}}
\newlabel{thm:aronszajn}{{3.13}{22}}
\newlabel{lem:RKHS}{{3.14}{22}}
\citation{NTK}
\citation{lem:funcDerivative}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Kernel Gradient Descent}{23}{}\protected@file@percent }
\newlabel{sec:KGD}{{3.4}{23}}
\newlabel{def:phi}{{3.17}{23}}
\newlabel{lem:phi}{{3.19}{24}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {5}{\ignorespaces Kernel Gradient Descent}}{25}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Kernel Approximation}{26}{}\protected@file@percent }
\newlabel{sec:approximation}{{3.5}{26}}
\newlabel{def:follow}{{3.24}{27}}
\newlabel{lem:evolution}{{3.25}{27}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Neural Tangent Kernel}{29}{}\protected@file@percent }
\newlabel{def:ntk}{{3.27}{29}}
\citation{Stieltjes}
\citation{Linear}
\newlabel{thm:stieltjes}{{3.32}{30}}
\newlabel{thm:linear}{{3.33}{30}}
\citation{Paper}
\citation{Paper}
\@writefile{toc}{\contentsline {section}{\numberline {4}Training in Low-Dimensional Subspaces}{34}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Approach}{34}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Low-dimensional parameter trajectory}}{34}{}\protected@file@percent }
\newlabel{fig:trajectory}{{4}{34}}
\citation{SVD}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Theory}{35}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Singular Value Decomposition}{35}{}\protected@file@percent }
\newlabel{thm:svd}{{4.1}{35}}
\newlabel{cor:svd}{{4.3}{35}}
\citation{SVD}
\newlabel{thm:eym}{{4.5}{36}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Dynamic Linear Dimensionality Reduction}{36}{}\protected@file@percent }
\newlabel{def:flow}{{4.6}{37}}
\newlabel{lem:flow}{{4.7}{37}}
\citation{SVD}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Methodology}{40}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Orthogonal Projections}{40}{}\protected@file@percent }
\newlabel{lem:orthProjection}{{4.8}{40}}
\citation{PCA}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}Principal Component Analysis}{41}{}\protected@file@percent }
\newlabel{sec:PCA}{{4.3.2}{41}}
\newlabel{thm:PCA}{{4.10}{42}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.3}Algorithm}{43}{}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {6}{\ignorespaces Dynamic Linear Dimensionality Reduction (DLDR)}}{43}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Numerical Experiments}{44}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{45}{}\protected@file@percent }
\citation{NTK}
\citation{Functionals}
\@writefile{toc}{\contentsline {section}{\numberline {7}Training in the Function Space}{46}{}\protected@file@percent }
\newlabel{sec:kernel}{{7}{46}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Functional Gradient Descent}{46}{}\protected@file@percent }
\newlabel{def:derivative}{{7.2}{47}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {7}{\ignorespaces Functional Gradient Descent}}{47}{}\protected@file@percent }
\citation{NTK}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}The Dual Space}{49}{}\protected@file@percent }
\citation{FunctionalAnalysis}
\newlabel{lem:projection}{{7.6}{51}}
\citation{FunctionalAnalysis}
\citation{FunctionalAnalysis}
\newlabel{cor:projection}{{7.7}{52}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Appendix}{54}{}\protected@file@percent }
\newlabel{cor:descent}{{8.3}{54}}
\newlabel{lem:coercivity}{{8.4}{54}}
\bibcite{Paper}{1}
\bibcite{GD}{2}
\bibcite{ConvexOptimization}{3}
\bibcite{BFGS}{4}
\bibcite{SGD}{5}
\bibcite{Adam}{6}
\bibcite{NTK}{7}
\bibcite{Functionals}{8}
\bibcite{FunctionalAnalysis}{9}
\bibcite{RKHS}{10}
\bibcite{Reproducing}{11}
\bibcite{Stieltjes}{12}
\bibcite{Linear}{13}
\bibcite{SVD}{14}
\bibcite{PCA}{15}
\gdef \@abspage@last{59}
